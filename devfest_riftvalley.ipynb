{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNNdm7ZI2A5dtmc9Gayoxil",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gerald-wambui/RentIn/blob/main/devfest_riftvalley.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = '/content'\n",
        "#/content/kaggle.json"
      ],
      "metadata": {
        "id": "svwSXAItHZf2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d alxmamaev/flowers-recognition"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KCcKsduHUxy",
        "outputId": "95acbd4b-c727-46e5-8ec0-0afa2f68eba1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /content/kaggle.json'\n",
            "Downloading flowers-recognition.zip to /content\n",
            " 96% 216M/225M [00:01<00:00, 118MB/s]\n",
            "100% 225M/225M [00:01<00:00, 121MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \\*.zip"
      ],
      "metadata": {
        "id": "oapVdC_uCLvw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "PWmEGI06BqCL",
        "outputId": "79b85700-110a-4f94-8cad-b16dccd9262e"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-f660a3e82199>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'content/flowers-recognition'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#/content/flowers-recognition.zip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'content/flowers-recognition'"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.chdir('content/flowers')\n",
        "print(os.listdir())#/content/flowers-recognition.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data visualisation and manipulation\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import style\n",
        "import seaborn as sns\n",
        "\n",
        "#model selection\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score,precision_score,recall_score,confusion_matrix,roc_curve,roc_auc_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras import layers, models\n",
        "import tensorflow as tf\n",
        "\n",
        "#preprocess.\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "#dl libraraies\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import Adam,SGD,Adagrad,Adadelta,RMSprop\n",
        "from keras.utils import to_categorical\n",
        "# specifically for cnn\n",
        "from keras.layers import Dropout, Flatten,Activation\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow as tf\n",
        "import random as rn\n",
        "# specifically for manipulating zipped images and getting numpy arrays of pixel values of images.\n",
        "import cv2\n",
        "import numpy as np\n",
        "import glob\n",
        "import os\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sys import getsizeof"
      ],
      "metadata": {
        "id": "p7p_1SByBstN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE=150\n",
        "FLOWER_DAISY_DIR='/content/flowers/daisy'\n",
        "FLOWER_SUNFLOWER_DIR='/content/flowers/sunflower'\n",
        "FLOWER_TULIP_DIR='/content/flowers/tulip'\n",
        "FLOWER_DANDI_DIR='/content/flowers/dandelion'\n",
        "FLOWER_ROSE_DIR='/content/flowers/rose'"
      ],
      "metadata": {
        "id": "4_CbUjOOB4cW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dictionary to store counts for each directory\n",
        "image_counts = {}\n",
        "\n",
        "# Loop through the directories and count images\n",
        "for directory, dir_name in zip([FLOWER_DAISY_DIR, FLOWER_SUNFLOWER_DIR, FLOWER_TULIP_DIR, FLOWER_DANDI_DIR, FLOWER_ROSE_DIR], ['Daisy', 'Sunflower', 'Tulip', 'Dandelion', 'Rose']):\n",
        "    image_paths = glob.glob(os.path.join(directory, '*.jpg'))\n",
        "    image_count = len(image_paths)\n",
        "    image_counts[dir_name] = image_count\n",
        "\n",
        "# Print the image counts for each directory\n",
        "for dir_name, count in image_counts.items():\n",
        "    print(f\"Directory '{dir_name}' contains {count} images.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ve5-uVXyJO1D",
        "outputId": "5da8ef32-5b01-453f-a66e-36f817517ccf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory 'Daisy' contains 764 images.\n",
            "Directory 'Sunflower' contains 733 images.\n",
            "Directory 'Tulip' contains 984 images.\n",
            "Directory 'Dandelion' contains 1052 images.\n",
            "Directory 'Rose' contains 784 images.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize empty lists for data and labels\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "# Define a function to load and preprocess images for a specific category\n",
        "def load_and_preprocess_category(category, directory):\n",
        "    image_paths = glob.glob(os.path.join(directory, '*.jpg'))\n",
        "    for image_path in image_paths:\n",
        "        img = cv2.imread(image_path)\n",
        "        if img is not None:\n",
        "            img = cv2.resize(img, (224, 224))  # Resize the image\n",
        "            img = img / 255.0  # Normalize pixel values\n",
        "            X.append(img)\n",
        "            y.append(category)\n",
        "\n",
        "# Call the function for each flower category\n",
        "load_and_preprocess_category('Daisy', FLOWER_DAISY_DIR)\n",
        "load_and_preprocess_category('Sunflower', FLOWER_SUNFLOWER_DIR)\n",
        "load_and_preprocess_category('Tulip', FLOWER_TULIP_DIR)\n",
        "load_and_preprocess_category('Dandelion', FLOWER_DANDI_DIR)\n",
        "load_and_preprocess_category('rose', FLOWER_DANDI_DIR)\n",
        "# Encode labels using LabelEncoder\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "\n",
        "# Convert the lists to NumPy arrays\n",
        "X = np.array(X)\n",
        "Y = np.array(y_encoded)"
      ],
      "metadata": {
        "id": "JJuM20e2JebJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "id": "SiF-n27YJ62Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "Y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOBVbVlxJxuA",
        "outputId": "fb15891c-fa9d-4113-c8a8-35ad1e93a25f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 4, 4, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(X))\n",
        "print(len(Y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYOTsMcwKWlU",
        "outputId": "9db51edd-b505-490c-e610-ad52d2ca96ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4585\n",
            "4585\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data into training (70%) and temporary data (30%)\n",
        "X_train, X_temp, Y_train, Y_temp = train_test_split(X, Y, test_size=0.30, random_state=42)\n",
        "\n",
        "# Split the temporary data into validation (15%) and testing (15%)\n",
        "X_val, X_test, Y_val, Y_test = train_test_split(X_temp, Y_temp, test_size=0.50, random_state=42)"
      ],
      "metadata": {
        "id": "88tLdvErKeJg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the CNN model\n",
        "model = keras.Sequential([\n",
        "    # Convolutional layer 1\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    # Convolutional layer 2\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    # Convolutional layer 3\n",
        "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    # Flatten the output for dense layers\n",
        "    layers.Flatten(),\n",
        "\n",
        "    # Dense layer 1\n",
        "    layers.Dense(128, activation='relu'),\n",
        "\n",
        "    # Output layer with softmax activation for classification\n",
        "    layers.Dense(5, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "KV8QCfwJKkH9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training & Evaluation\n",
        "\n",
        "model.fit(X_train,Y_train, epochs=10 , batch_size=32 )"
      ],
      "metadata": {
        "id": "jUfwh-8tKpS8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate (X_test,Y_test)\n",
        "print(\"Test Score:\",score[0])\n",
        "print(\"Test Accuracy:\",score[1])"
      ],
      "metadata": {
        "id": "SoTWnXpQKzNZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_file_size(file_path):\n",
        "    size = os.path.getsize(file_path)\n",
        "    return size"
      ],
      "metadata": {
        "id": "V_AOen8PK4Pg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_bytes(size, unit=None):\n",
        "    if unit == \"KB\":\n",
        "        return print('File size: ' + str(round(size / 1024, 3)) + ' Kilobytes')\n",
        "    elif unit == \"MB\":\n",
        "        return print('File size: ' + str(round(size / (1024 * 1024), 3)) + ' Megabytes')\n",
        "    else:\n",
        "        return print('File size: ' + str(size) + ' bytes')"
      ],
      "metadata": {
        "id": "geN059hsK_dM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "KERAS_MODEL_NAME = \"tf_model_flowers_rec.h5\"\n",
        "model.save(KERAS_MODEL_NAME)"
      ],
      "metadata": {
        "id": "eH7TPDVILHia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "convert_bytes(get_file_size(KERAS_MODEL_NAME), \"MB\")"
      ],
      "metadata": {
        "id": "7LxxNG6oPjXC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras_model_size = get_file_size(KERAS_MODEL_NAME)\n",
        "TF_LITE_MODEL_FILE_NAME = \"tf_lite_model.tflite\"\n",
        "\n"
      ],
      "metadata": {
        "id": "2GWLrTYRPt7L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf_lite_converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = tf_lite_converter.convert()\n",
        "tflite_model_name = \"tf_lite_model.tflite\"\n",
        "open(tflite_model_name, \"wb\").write(tflite_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzLBjDIpP8BB",
        "outputId": "a91bea44-b483-4324-dd59-7eab2dddc824"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13225216"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "convert_bytes(get_file_size(TF_LITE_MODEL_FILE_NAME), \"KB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7EXIALnRQLVG",
        "outputId": "2f3e3472-fafa-47c7-a8e1-7dd811fa1d45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File size: 12915.25 Kilobytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tflite_file_size = get_file_size(TF_LITE_MODEL_FILE_NAME)"
      ],
      "metadata": {
        "id": "Ql5MSKRAQT0x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interpreter = tf.lite.Interpreter(model_path = TF_LITE_MODEL_FILE_NAME)\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "print(\"Input Shape:\", input_details[0]['shape'])\n",
        "print(\"Input Type:\", input_details[0]['dtype'])\n",
        "print(\"Output Shape:\", output_details[0]['shape'])\n",
        "print(\"Output Type:\", output_details[0]['dtype'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCDdJXfWQYOF",
        "outputId": "07190946-4378-42db-ac3d-3d2c604fc1b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Shape: [  1 128 128   3]\n",
            "Input Type: <class 'numpy.float32'>\n",
            "Output Shape: [1 5]\n",
            "Output Type: <class 'numpy.float32'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "interpreter.resize_tensor_input(input_details[0]['index'], (688, 128, 128, 3))\n",
        "interpreter.resize_tensor_input(output_details[0]['index'], (688, 5))\n",
        "interpreter.allocate_tensors()\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "print(\"Input Shape:\", input_details[0]['shape'])\n",
        "print(\"Input Type:\", input_details[0]['dtype'])\n",
        "print(\"Output Shape:\", output_details[0]['shape'])\n",
        "print(\"Output Type:\", output_details[0]['dtype'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-tRmvwbQmHD",
        "outputId": "a8f16d23-fe83-46a1-91f1-cdeb1784698d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Shape: [688 128 128   3]\n",
            "Input Type: <class 'numpy.float32'>\n",
            "Output Shape: [688   5]\n",
            "Output Type: <class 'numpy.float32'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3D6VWihSB-3",
        "outputId": "48ea33d9-5d2b-4d23-f603-907fb7a85bd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('float64')"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_imgs_numpy = np.array(X_test, dtype=np.float32)\n",
        "test_imgs_numpy.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8m6XswVSZ57",
        "outputId": "38f39810-c715-4691-8fe1-a855ecbea56a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('float32')"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "interpreter.set_tensor(input_details[0]['index'], test_imgs_numpy)\n",
        "interpreter.invoke()\n",
        "tflite_model_predictions = interpreter.get_tensor(output_details[0]['index'])\n",
        "print(\"Prediction results shape:\", tflite_model_predictions.shape)\n",
        "prediction_classes = np.argmax(tflite_model_predictions, axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwoHXvP2SnDU",
        "outputId": "8a60ca5d-4a92-47cf-f4de-dded60f4dbd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction results shape: (688, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Assuming test_imgs_numpy is your input data and Y is the ground truth labels\n",
        "\n",
        "# Resize the input and output tensor shapes in the interpreter\n",
        "interpreter.resize_tensor_input(input_details[0]['index'], (688, 128, 128, 3))\n",
        "interpreter.resize_tensor_input(output_details[0]['index'], (688, 5))\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Get the updated input and output details after resizing\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "print(\"Input Shape:\", input_details[0]['shape'])\n",
        "print(\"Input Type:\", input_details[0]['dtype'])\n",
        "print(\"Output Shape:\", output_details[0]['shape'])\n",
        "print(\"Output Type:\", output_details[0]['dtype'])\n",
        "\n",
        "# Set the input tensor with your test data\n",
        "interpreter.set_tensor(input_details[0]['index'], test_imgs_numpy)\n",
        "\n",
        "# Invoke the interpreter to make predictions\n",
        "interpreter.invoke()\n",
        "\n",
        "# Get the predictions from the output tensor\n",
        "tflite_model_predictions = interpreter.get_tensor(output_details[0]['index'])\n",
        "print(\"Prediction results shape:\", tflite_model_predictions.shape)\n",
        "\n",
        "# Assuming Y contains ground truth labels, calculate accuracy\n",
        "prediction_classes = np.argmax(tflite_model_predictions, axis=1)\n",
        "acc = accuracy_score(prediction_classes, Y)\n",
        "\n",
        "# Print the accuracy\n",
        "print(\"Accuracy:\", acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "iNXWO4ZxjUfq",
        "outputId": "f8da49f1-5e97-4b1d-9edd-c5f5b3c88b2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Shape: [688 128 128   3]\n",
            "Input Type: <class 'numpy.float32'>\n",
            "Output Shape: [688   5]\n",
            "Output Type: <class 'numpy.float32'>\n",
            "Prediction results shape: (688, 5)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-f1d1a5d7328e>\u001b[0m in \u001b[0;36m<cell line: 32>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# Assuming Y contains ground truth labels, calculate accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mprediction_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtflite_model_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# Print the accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"multilabel\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \"\"\"\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y_true\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y_pred\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    395\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    398\u001b[0m             \u001b[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m             \u001b[0;34m%\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [688, 4585]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(prediction_classes)\n",
        "acc = accuracy_score(prediction_classes, Y)\n",
        "#score = tflite_model.evaluate (X_test,Y_test)\n",
        "#print(\"Test Score:\",score[0])\n",
        "#print(\"Test Accuracy:\",score[1])"
      ],
      "metadata": {
        "id": "bxYkWhA1S_TG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tflite_file_size/keras_model_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UoEcFkKbWeiz",
        "outputId": "df751d15-7580-4f2b-9387-d1ab4d4b68b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3329913754502171"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ABZxRSq6XEjp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf_lite_converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tf_lite_converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "tf_lite_converter.target_spec.supported_types = [tf.float16]\n",
        "tflite_model = tf_lite_converter.convert()"
      ],
      "metadata": {
        "id": "wbEDaYlhW9Ne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TF_LITE_MODEL_FLOAT_16_FILE_NAME = \"tf_quantized_flowers.tflite\"\n",
        "tflite_model_name = TF_LITE_MODEL_FLOAT_16_FILE_NAME\n",
        "open(tflite_model_name, \"wb\").write(tflite_model)"
      ],
      "metadata": {
        "id": "DtdCJpNZXG_T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "convert_bytes(get_file_size(TF_LITE_MODEL_FLOAT_16_FILE_NAME), \"KB\")"
      ],
      "metadata": {
        "id": "IKm5FP8WXL4W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tflite_float_16_file_size = get_file_size(TF_LITE_MODEL_FLOAT_16_FILE_NAME)"
      ],
      "metadata": {
        "id": "tVYVlYoaXVHT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tflite_float_16_file_size/keras_model_size"
      ],
      "metadata": {
        "id": "Jgsc-TqmXa8J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "pZ2HJngQXgGs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TF_LITE_QUANT_MODEL_NAME = \"tf_lite_quant_model.tflite\""
      ],
      "metadata": {
        "id": "jSCMhZtVXb6V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf_lite_converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tf_lite_converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
        "tflite_model = tf_lite_converter.convert()"
      ],
      "metadata": {
        "id": "FPaifflcXh2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tflite_model_name = \"tf_lite_quant_model.tflite\"\n",
        "open(tflite_model_name, \"wb\").write(tflite_model)"
      ],
      "metadata": {
        "id": "50cPMe7pXlWI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "convert_bytes(get_file_size(TF_LITE_SIZE_QUANT_MODEL_FILE_NAME), \"KB\")"
      ],
      "metadata": {
        "id": "-c8flVlxXo97"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tflite_float_quant_file_size = get_file_size(TF_LITE_SIZE_QUANT_MODEL_FILE_NAME)"
      ],
      "metadata": {
        "id": "__ledG6EXsak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tflite_float_quant_file_size/keras_model_size"
      ],
      "metadata": {
        "id": "h5YvkfuRXwLc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tflite_float_quant_file_size/ tflite_float_16_file_size"
      ],
      "metadata": {
        "id": "5UcyLUTpXzSQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "JqKEEZ2qX22-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_model_optimization as tfmot\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "   ...\n",
        "])\n",
        "# Quantize the entire model.\n",
        "quantized_model = tfmot.quantization.keras.quantize_model(model)\n",
        "\n",
        "# Continue with training as usual.\n",
        "quantized_model.compile(...)\n",
        "quantized_model.fit(...)"
      ],
      "metadata": {
        "id": "Az4x9TpFX3Iv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}